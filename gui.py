import streamlit as st
import os
import subprocess
import platform
from core.paper_ops import add_paper, batch_organize
from core.image_ops import index_images
from core.db import VectorDB
from core.models import ModelLoader, get_clip_text_embedding


# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="æœ¬åœ° AI æ™ºèƒ½åŠ©æ‰‹", layout="wide", page_icon="ğŸ¤–")

st.title("ğŸ¤– æœ¬åœ° AI æ™ºèƒ½æ–‡çŒ®ä¸å›¾åƒç®¡ç†åŠ©æ‰‹")

# --- ä¾§è¾¹æ ï¼šåŠŸèƒ½é€‰æ‹© ---
st.sidebar.header("åŠŸèƒ½å¯¼èˆª")
# ä½¿ç”¨ radio ç»„ä»¶ï¼Œæ‰€æœ‰é€‰é¡¹ç›´æ¥æ˜¾ç¤º
menu = st.sidebar.radio(
    "è¯·é€‰æ‹©åŠŸèƒ½:",
    ["â• æ·»åŠ å•ç¯‡æ–‡çŒ®", "ğŸ“‚ æ‰¹é‡æ•´ç†æ–‡çŒ®", "ğŸ“„ è¯­ä¹‰æœæ–‡çŒ®", "ğŸ”„ æ›´æ–°å›¾ç‰‡ç´¢å¼•", "ğŸ–¼ï¸ ä»¥æ–‡æœå›¾"],
    index=0
)

st.sidebar.markdown("---")
st.sidebar.info("æç¤º: \nä½¿ç”¨å·¦ä¾§å¯¼èˆªæ åˆ‡æ¢ä¸åŒåŠŸèƒ½æ¨¡å—ã€‚")


# --- æœç´¢é€»è¾‘å‡½æ•° ---
def st_search_paper(query, threshold):
    collection = VectorDB.get_collection("papers")
    model = ModelLoader.get_text_model()
    query_emb = model.encode(query).tolist()

    results = collection.query(query_embeddings=[query_emb], n_results=10)

    if not results['documents'] or not results['documents'][0]:
        st.warning("æœªæ‰¾åˆ°ä»»ä½•å†…å®¹ã€‚")
        return

    found_count = 0
    for i, doc in enumerate(results['documents'][0]):
        dist = results['distances'][0][i]
        similarity = 1 - dist

        if similarity >= threshold:
            found_count += 1
            meta = results['metadatas'][0][i]

            # ä½¿ç”¨ expander æ˜¾ç¤º
            with st.expander(f"[{found_count}] {meta['filename']} (ç›¸ä¼¼åº¦: {similarity:.4f})"):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.markdown(f"**åˆ†ç±»**: `{meta['category']}` | **é¡µç **: `{meta['page']}`")
                    st.info(doc)  # æ˜¾ç¤ºå®Œæ•´ç‰‡æ®µ
                    st.text(f"è·¯å¾„: {meta['path']}")

    if found_count == 0:
        st.warning(f"æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦ > {threshold} çš„ç»“æœã€‚")


def st_search_image(query, threshold, n_results=10):
    collection = VectorDB.get_collection("images")
    query_emb = get_clip_text_embedding(query)
    results = collection.query(query_embeddings=[query_emb], n_results=n_results)

    if not results['ids'] or not results['ids'][0]:
        st.warning("æœªæ‰¾åˆ°ç›¸å…³å›¾ç‰‡ã€‚")
        return

    cols = st.columns(3)
    count = 0
    for i, _ in enumerate(results['ids'][0]):
        dist = results['distances'][0][i]
        similarity = 1 - dist

        if similarity >= threshold:
            meta = results['metadatas'][0][i]
            with cols[count % 3]:
                if os.path.exists(meta['path']):
                    st.image(meta['path'], caption=f"ç›¸ä¼¼åº¦: {similarity:.4f}")
                    st.caption(meta['filename'])

                else:
                    st.error("å›¾ç‰‡æ–‡ä»¶ä¸¢å¤±")
            count += 1

    if count == 0:
        st.warning(f"æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦ > {threshold} çš„å›¾ç‰‡ã€‚")


# --- ä¸»ç•Œé¢é€»è¾‘ ---

if menu == "ğŸ“„ è¯­ä¹‰æœæ–‡çŒ®":
    st.header("ğŸ” è¯­ä¹‰æœç´¢æ–‡çŒ®")
    with st.form("search_form"):
        c1, c2 = st.columns([4, 1])
        with c1:
            query = st.text_input("è¯·è¾“å…¥é—®é¢˜æˆ–å…³é”®è¯")
        with c2:
            threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.0, 1.0, 0.4, 0.05)
        submitted = st.form_submit_button("ğŸ” å¼€å§‹æœç´¢")

    if submitted and query:
        with st.spinner("æ­£åœ¨æœç´¢çŸ¥è¯†åº“..."):
            st_search_paper(query, threshold)

elif menu == "ğŸ–¼ï¸ ä»¥æ–‡æœå›¾":
    st.header("ğŸ¨ ä»¥æ–‡æœå›¾")
    with st.form("img_form"):
        c1, c2 = st.columns([4, 1])
        with c1:
            query = st.text_input("è¯·è¾“å…¥å›¾ç‰‡æè¿°")
        with c2:
            threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.0, 1.0, 0.25, 0.05)
        submitted = st.form_submit_button("ğŸ–¼ï¸ æœç´¢å›¾ç‰‡")

    if submitted and query:
        with st.spinner("æ­£åœ¨åˆ†æå›¾ç‰‡åº“..."):
            st_search_image(query, threshold)

elif menu == "â• æ·»åŠ å•ç¯‡æ–‡çŒ®":
    st.header("ğŸ“¤ æ·»åŠ å•ç¯‡æ–‡çŒ®")
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type="pdf")
    topics_str = st.text_input("åˆ†ç±»ä¸»é¢˜ (é€—å·åˆ†éš”)", value="NLP, CV, RL, RecSys")

    if st.button("å¤„ç†å¹¶å½’æ¡£") and uploaded_file:
        with st.spinner("æ­£åœ¨è¯»å–ã€åˆ†ç±»å¹¶å»ºç«‹ç´¢å¼•..."):
            os.makedirs("data", exist_ok=True)
            temp_path = os.path.join("data", uploaded_file.name)
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            add_paper(temp_path, topics_str)
            st.success(f"æˆåŠŸå¤„ç†: {uploaded_file.name}")
            if os.path.exists(temp_path):
                os.remove(temp_path)

elif menu == "ğŸ“‚ æ‰¹é‡æ•´ç†æ–‡çŒ®":
    st.header("ğŸ“š æ‰¹é‡æ•´ç†æ–‡ä»¶å¤¹")
    folder_path = st.text_input("è¯·è¾“å…¥å¾…æ•´ç†çš„æ–‡ä»¶å¤¹ç»å¯¹è·¯å¾„")
    topics_str = st.text_input("åˆ†ç±»ä¸»é¢˜", value="Collaborative Filtering, Deep Learning, Graph Neural Networks")

    if st.button("å¼€å§‹æ•´ç†") and folder_path:
        if os.path.exists(folder_path):
            with st.spinner("æ­£åœ¨æ‰¹é‡æ‰«æå’Œå¤„ç†..."):
                batch_organize(folder_path, topics_str)
                st.success("æ‰¹é‡æ•´ç†å®Œæˆï¼")
        else:
            st.error("è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ã€‚")

elif menu == "ğŸ”„ æ›´æ–°å›¾ç‰‡ç´¢å¼•":
    st.header("ğŸ–¼ï¸ æ›´æ–°å›¾ç‰‡ç´¢å¼•")
    source_dir = st.text_input("å›¾ç‰‡æºæ–‡ä»¶å¤¹")

    if st.button("å¼€å§‹å»ºç«‹ç´¢å¼•"):
        with st.spinner("æ­£åœ¨æ‰«æå›¾ç‰‡å¹¶è®¡ç®—å‘é‡..."):
            index_images(source_dir if source_dir else None)
            st.success("ç´¢å¼•æ›´æ–°å®Œæ¯•ï¼")

# --- é¡µè„š ---
st.markdown("---")
st.caption("Local AI Agent | Powered by Sentence-Transformers & CLIP & ChromaDB")